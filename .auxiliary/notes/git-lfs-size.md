# Git LFS Integration for Ingest Command

## Problem Statement

The ingest command copies files from source directories, some of which may be large (>100KB). These large files should be tracked via Git LFS to keep the repository efficient, but currently this requires manual detection and `.gitattributes` configuration.

## Design Goals

1. **Automatic detection**: Identify large files during ingestion without user intervention
2. **Specific patterns**: Generate precise `.gitattributes` patterns to avoid over-tracking
3. **No Git operations**: Tool should only update `.gitattributes`, not perform Git commands
4. **Clear reporting**: Inform user about detected large files and generated patterns

## Requirements

### Size Threshold
- **100KB (102,400 bytes)**: Files at or above this size should be tracked via Git LFS
- Rationale: Most scripts should be under 100KB; larger files are typically data/samples

### Pattern Generation Strategy
- **Specific file patterns**: Use actual filenames/paths, not broad extension-based rules
- Example: `ingests/project-name/specific-file.html` rather than `ingests/**/*.html`
- Rationale: Prevents unnecessary LFS tracking which can degrade performance

### Behavior
- **Automatic**: No flag required, always enabled
- **Non-invasive**: Only updates `.gitattributes`, does not perform Git operations
- **Idempotent**: Safe to run multiple times, deduplicates patterns

## Implementation Design

### 1. Detection Phase

After file ingestion completes, scan all copied files:

```python
def _detect_large_files(
    copied_files: __.cabc.Mapping[ __.Path, __.Path ],
    threshold: int = 102400,  # 100KB
) -> __.cabc.Sequence[ tuple[ __.Path, int ] ]:
    ''' Detects files exceeding LFS size threshold.

        Returns sequence of (destination_path, file_size) tuples.
    '''
    large_files = [ ]
    for destination in copied_files.values( ):
        try:
            size = destination.stat( ).st_size
            if size >= threshold:
                large_files.append( ( destination, size ) )
        except OSError:
            continue
    return tuple( large_files )
```

### 2. Pattern Generation

Generate specific `.gitattributes` patterns for each large file:

```python
def _generate_lfs_patterns(
    large_files: __.cabc.Sequence[ tuple[ __.Path, int ] ],
    repo_root: __.Path,
) -> __.cabc.Sequence[ str ]:
    ''' Generates Git LFS patterns for large files.

        Returns sequence of .gitattributes entries with relative paths.
    '''
    patterns = [ ]
    for file_path, size in large_files:
        # Generate relative path from repo root
        try:
            relative = file_path.relative_to( repo_root )
        except ValueError:
            # File outside repo, skip
            continue
        pattern = (
            f"{relative} filter=lfs diff=lfs merge=lfs -text  "
            f"# {size // 1024}KB"
        )
        patterns.append( pattern )
    return tuple( patterns )
```

### 3. `.gitattributes` Update

Append patterns to `.gitattributes` with deduplication:

```python
def _update_gitattributes(
    patterns: __.cabc.Sequence[ str ],
    gitattributes_path: __.Path,
) -> None:
    ''' Updates .gitattributes file with LFS patterns.

        Deduplicates patterns and adds section marker.
    '''
    # Read existing content
    if gitattributes_path.exists( ):
        existing_content = gitattributes_path.read_text( )
        existing_lines = set( existing_content.splitlines( ) )
    else:
        existing_content = ""
        existing_lines = set( )

    # Filter out duplicates
    new_patterns = [
        pattern for pattern in patterns
        if pattern.split( '#' )[ 0 ].strip( ) not in
           { line.split( '#' )[ 0 ].strip( ) for line in existing_lines }
    ]

    if not new_patterns:
        return

    # Append new patterns
    with gitattributes_path.open( 'a' ) as f:
        if existing_content and not existing_content.endswith( '\n' ):
            f.write( '\n' )
        f.write( '\n# Generated by lmscribbles ingest\n' )
        for pattern in new_patterns:
            f.write( f"{pattern}\n" )
```

### 4. Reporting

Add LFS information to `IngestResult`:

```python
class IngestResult( __.immut.DataclassObject ):
    ''' Results of ingestion operation. '''

    copied: __.immut.Dictionary[ __.Path, __.Path ]
    skipped: __.immut.Dictionary[ __.Path, str ]
    renamed: __.immut.Dictionary[ __.Path, PathPair ]
    failed: __.immut.Dictionary[ __.Path, str ]
    warnings: __.cabc.Sequence[ str ]
    lfs_files: __.cabc.Sequence[ tuple[ __.Path, int ] ]  # NEW

    def render_as_text( self ) -> str:
        ''' Renders result as human-readable text. '''
        lines: list[ str ] = [ ]
        # ... existing rendering logic ...

        if self.lfs_files:
            lines.append( f"\nLarge files detected ({len( self.lfs_files )}):" )
            lines.append( "  Updated .gitattributes with Git LFS patterns." )
            lines.append( "  Run 'git rm --cached <file> && git add <file>' "
                         "to migrate to LFS." )
            for file_path, size in self.lfs_files:
                size_kb = size // 1024
                lines.append( f"  {file_path} ({size_kb}KB)" )

        return '\n'.join( lines )
```

## Integration Points

### In `IngestCommand.__call__()`

```python
async def __call__( self ) -> IngestResult:
    ''' Executes ingestion command. '''
    # ... existing ingestion logic ...

    # Detect large files and update .gitattributes
    lfs_files = ( )
    if copied:
        repo_root = __.Path.cwd( )
        large_files = _detect_large_files( copied )
        if large_files:
            lfs_files = large_files
            patterns = _generate_lfs_patterns( large_files, repo_root )
            gitattributes = repo_root / '.gitattributes'
            try:
                _update_gitattributes( patterns, gitattributes )
            except OSError as exception:
                warnings.append(
                    f"Failed to update .gitattributes: {exception}" )

    return IngestResult(
        copied = __.immut.Dictionary( copied ),
        skipped = __.immut.Dictionary( skipped ),
        renamed = __.immut.Dictionary( renamed ),
        failed = __.immut.Dictionary( failed ),
        warnings = tuple( warnings ),
        lfs_files = lfs_files,
    )
```

## Example Output

```
Copied 12 file(s):
  /path/to/source/file1.py -> ingests/project/file1.py
  /path/to/source/large.html -> ingests/project/large.html
  ...

Large files detected (2):
  Updated .gitattributes with Git LFS patterns.
  Run 'git rm --cached <file> && git add <file>' to migrate to LFS.
  ingests/project/large.html (199KB)
  ingests/project/analysis.json (358KB)
```

## Future Enhancements

1. **Configurable threshold**: Add `--lfs-threshold` CLI option
2. **Dry-run preview**: Show what would be added to `.gitattributes` without writing
3. **Pattern optimization**: Detect common patterns and suggest wildcards
4. **Git integration script**: Generate shell script with exact `git rm/add` commands

## Migration Path

For existing large files already committed:
1. User runs ingest (updates `.gitattributes`)
2. User manually runs: `git rm --cached <files> && git add <files>`
3. User commits the LFS migration

This keeps Git operations under explicit user control while automating the detection and configuration.
